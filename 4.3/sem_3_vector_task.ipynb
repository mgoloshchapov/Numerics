{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Быстрое сжатие векторного пространства\n",
    "\n",
    "Одна из часто возникающих задач - сжатие векторного пространства с приближённым сохранением некоторых свойств (например, взаимного расстояния между векторами). В некоторых приложениях (например - в обработке естественных языков) исходное пространство имеет очень высокую размерность и оптимальное сжатие (например, методом главных компонент или градиентным спуском) потребует существенного расхода процессорного времени и памяти. \n",
    "\n",
    "В данной задаче на примере реальных данных показывается эффективный способ провести такое сжатие с сохранением взаимного расстояния между векторами.\n",
    "\n",
    "### Исходные данные\n",
    "\n",
    "Исходные данные для задачи содержатся в файле ppmi_vectors.txt. Это разреженные семантические векторы для 4х групп слов. Они имеют такой вид:\n",
    "```\n",
    "Слово_1\n",
    "(номер координаты 1_1, значение)\n",
    "(номер координаты 1_2, значение)\n",
    "...\n",
    "(номер координаты 1_M1, значение)\n",
    "\n",
    "Слово_2\n",
    "(номер координаты 2_1, значение)\n",
    "(номер координаты 2_2, значение)\n",
    "...\n",
    "(номер координаты 2_M2, значение)\n",
    "```\n",
    "номера координат неупорядочены, вектора не нормированы. Размерность исходного пространства 1 400 000. Семантические векторы представляют собой столбцы матрицы взаимной информации слов ( [ppmi, positive pointwise mutual information](https://en.wikipedia.org/wiki/Pointwise_mutual_information) ). Здесь приведены лишь некоторые столбцы т.к. сама матрица слишком велка для учебной задачи (~ 1 400 000 x 5 000 ~ 20гб). Сама матрица была получена путём вычисления ppmi для слов на 1гб русскоязычных текстов. \n",
    "\n",
    "За предоставление данных авторы курса выражают признательность коллективу лаборатории когнитивных архитектур МФТИ и, в частности, Фахрутдинову Тимуру.\n",
    "\n",
    "Тоже выражаю респект Тимуру, классный чел\n",
    "\n",
    "### Постановка задачи\n",
    "\n",
    "Оказывается, если исходные вектора просто умножить на фиксированную случайную матрицу, то расстояния между ними с хорошей точностью сохранятся. Более точно, пусть в исходном пространстве размерности $N$ имелись нормированные вектора $word_1$ и $word_2$. Пусть $R$ - случайная матрица $M$ X $N$, элементы которой равномерно распределены на отрезке $[-1, 1]$. Тогда при достаточно больших M и N имеет место приближённое равенство:\n",
    "\n",
    "$$ (word_1, word_2) \\approx \\dfrac{(R \\cdot word_1, R \\cdot word_2)}{\\sqrt{(R \\cdot word_1, R \\cdot word_1) (R \\cdot word_2, R \\cdot word_2)}} $$\n",
    "\n",
    "Или, обозначив нормированные новые вектора \n",
    "\n",
    "$$ word_1' := \\dfrac{word_1}{\\sqrt{(R \\cdot word_1, R \\cdot word_1)}};\\ \\ \\ word_2' := \\dfrac{word_2}{\\sqrt{(R \\cdot word_2, R \\cdot word_2)}}$$\n",
    "\n",
    "Имеем\n",
    "$$ (word_1, word_2) \\approx  (word_1', word_2') $$\n",
    "\n",
    "1. Дополните код в ячейках ниже в соответствии с комментариями. Итого вы должны на нескольких примерах продемонстрировать, что при сжатии исходного пространства до размерности 1024 указанным выше способом, \"синонимичные\" слова (те, нормированные семантические вектора которых близки) остаются \"синонимичными\", а те, которые \"синонимичными\" не являлись - не не становятся \"синонимами\".\n",
    "\n",
    "2. По нескольким точкам постройте график зависимости ошибки от размерности финального пространства (может потребовать значительного компьютерного времени).\n",
    "\n",
    "3. (*)Теоретически выведите приближённое равенство $ (word_1, word_2) \\approx  (word_1', word_2') $. Какие условия для него нужны и каковы асимптотики ошибки? Сверьте с п. 2 \n",
    "\n",
    "П.3 не является обязательным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Допишите код, который будет загружать данные из файла \"ppmi_vectors.txt\"\n",
    "# в словарь words_vectors с разреженными семантическими векторами\n",
    "\n",
    "# выбираем удобный класс разреженных векторов\n",
    "# при проблемах с импортом класса - воспользуйтесь рекомендацией по ссылке\n",
    "# https://github.com/scikit-learn/scikit-learn/issues/16727\n",
    "from scipy.sparse import dok_array \n",
    "import re # для загрузки данных будут удобны регулярные выражения\n",
    "import numpy as np\n",
    "vetors_file = open(\"ppmi_vectors.txt\", \"r\")\n",
    "vector_space_size = 1400*1000\n",
    "lines = vetors_file.readlines()\n",
    "\n",
    "i = 0\n",
    "words_vectors = dict()\n",
    "current_word = \"\"\n",
    "# Разреженные вектора представляются матрицами размерами Nx1\n",
    "# Это не то же самое, что векторы длины N\n",
    "current_vect = dok_array((vector_space_size, 1),dtype = np.float32)\n",
    "for line in lines:\n",
    "    i += 1\n",
    "    word_m = re.match(r\"[а-яА-Я]{1,100}\", line) # ищем слово\n",
    "    if word_m is not None: # началось новое слово\n",
    "        if current_word != \"\": \n",
    "            words_vectors[current_word] = current_vect\n",
    "        current_word = word_m.group(0) # запомнили новое слово\n",
    "        # Создаём под него чистый разреженный вектор\n",
    "        current_vect = dok_array((vector_space_size, 1),dtype = np.float32)\n",
    "\n",
    "        \n",
    "    vect_component_m = re.match(r\"[\\(\\)0-9\\.\\,\\s]{1,100}\", line)\n",
    "    if vect_component_m is not None: # обнаружили очередную компоненту вектора\n",
    "        vect_component = vect_component_m.group(0)\n",
    "        axis_m  = re.search(r\"[0-9]{1,30}\", vect_component)\n",
    "        if axis_m is not None:\n",
    "            axis    = int(axis_m.group(0)) # записали номер оси\n",
    "            value_m = re.search(r\"[0-9]{1,30}\\.[0-9]{1,30}\", vect_component)\n",
    "            if value_m is not None:\n",
    "                value   = float(value_m.group(0)) # записали значение\n",
    "                # добавьте значение в словарь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Иван', 'Николай', 'Александр', 'Михаил', 'Василий', 'Миллион', 'Миллиард', 'Тысяча', 'Пять', 'Шесть', 'Семь', 'Восемь', 'России', 'РФ', 'СССР', 'Германии', 'ЦСКА', 'Динамо', 'Локомотив'])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# выведите все слова, представленные в словаре"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сохраняться при сжатии пространства будет нормированное скалярное произведение\n",
    "def normed_dot(words_vectors, word1, word2):\n",
    "    # Напишите функцию, принимающую на вход словарь разреженных векторов,\n",
    "    # и два слова, а возвращающую скалярное произведение нормированных векторов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2493515654.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[121], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    rand_vect = # задаёте строку матрицы R (случайные числа на отрезке -1, 1)\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Во время сжатия вся матрица перехода не хранится в памяти, а генерируется построчно\n",
    "# т.к. её минимальный объём (float16 size)*vector_space_size*final_space_size = \n",
    "# 2*1 024*1 400 000 ~ 3*10^9 байт ~ 3гб (для float32 и final_space_size = 4096 уже 25гб)\n",
    "final_space_size = 1024 #4096\n",
    "new_words_vectors = dict()\n",
    "for word in words_vectors.keys():\n",
    "    new_words_vectors[word] = np.zeros((final_space_size, 1))\n",
    "for i in range(final_space_size):\n",
    "    rand_vect = # задаёте строку матрицы R (случайные числа на отрезке -1, 1)\n",
    "    for word in words_vectors.keys():\n",
    "        new_words_vectors[word][i] = # умножьте rand_vect на исходный вектор \n",
    "    if (i % 100 == 0):\n",
    "        print(round(i/final_space_size*100), \"% done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Выведите по крайней мере 4 примера, сравнивающих скалярные произведения слов \n",
    "# из разных смысловых групп и продемонстрируйте, что смысловые группы не перемешались"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (2605310473.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[123], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    # в смысле сохранения скалярного произведения между различными нормированными векторами\u001b[0m\n\u001b[1;37m                                                                                           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def mean_error(words_vectors, new_words_vectors):\n",
    "    # Напишите функцию подсчитывающую среднеквадратичную ошибку сжатия пространства \n",
    "    # в смысле сохранения скалярного произведения между различными нормированными векторами"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03176239287802527"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_error(words_vectors, new_words_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# По нескольким точкам постройте график зависимости этой ошибки от размерности финального пространства"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
